---
title: "Text To Image Generation In DCGAN and Stable Diffusion Model"
collection: publications
category: conferences
permalink: /publication/2024-01-01-paper-text-number-4
excerpt: 'In the battle against widespread online misinformation, a growing problem is text-image inconsistency, where images are misleadingly paired with texts with different intent or meaning. '
date: 2024-01-01
venue: ' We explore the DCGAN model and stable diffusion
 model to implement text-to-image generation. We imple
ment, train, and test both modelsâ€™ by using the CLIP ViT
B/32 model to implement the text embedding. We trained
 the DCGAN and the stable diffusion models on the MNIST
 dataset and used the string representation of digits 0-9 as
 text input. Moreover, we chose the inception score model
 inceptionv3 as a metric to evaluate the performance of mod
els. Finally, we find the DCGAN model image quality per
formance is better than the stable diffusion models but the
 diffusion model can outperform the DCGAN model in time
 efficiency. In future work, we plan to extract the discrimi
nator of the DCGAN model to the stale diffusion model to
 improve the denoising process performance.'
paperurl: 'http://zhouzhou38.github.io/files/Text_to_Image_generation_In_DCGAN_and_Stable_Diffusion_Model3.pdf'
citation: ''
---

The contents above will be part of a list of publications, if the user clicks the link for the publication than the contents of section will be rendered as a full page, allowing you to provide more information about the paper for the reader. When publications are displayed as a single page, the contents of the above "citation" field will automatically be included below this section in a smaller font.
